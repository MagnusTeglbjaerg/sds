{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** In most sessions you will be solving exercises posed in a Jupyter notebook that looks like this one. Because you are cloning a Github repository that only we can push to, you should **NEVER EDIT** any of the files you pull from Github. Instead, what you should do, is either make a new notebook and write your solutions in there, or **make a copy of this notebook and save it somewhere else** on your computer, not inside the `sds` folder that you cloned, so you can write your answers in there. If you edit the notebook you pulled from Github, those edits (possible your solutions to the exercises) may be overwritten and lost the next time you pull from Github. This is important, so don't hesitate to ask if it is unclear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-23T15:30:03.634114Z",
     "start_time": "2017-08-23T15:30:03.629294Z"
    }
   },
   "source": [
    "# Exercise Set 9: Parsing and Information Extraction\n",
    "\n",
    "*Morning, August 17, 2018*\n",
    "\n",
    "In this Exercise Set we shall develop our webscraping skills even further by practicing navigating html trees using BeautifoulSoup and furthermore train extracting information from raw text with no html tags to help, using regular expressions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Section 9.1: Parsing a Table from HTML using BeautifulSoup.\n",
    "\n",
    "Yesterday I showed you a neat little prepackaged function in pandas that did all the work. However today we should learn the mechanics of it. *(It is not just for educational purposes, sometimes the package will not do exactly as you want.)*\n",
    "\n",
    "We hit the Basketball stats page from yesterday again: https://www.basketball-reference.com/leagues/NBA_2018.html.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 9.1.1:** Here we practice simply locating the table node of interest using the `find` method build into BeautifoulSoup. But first we have to fetch the HTML using the `requests` module. Parse the tree using `BeautifulSoup`. And then use the **>Inspector<** tool (* right click on the table < press inspect element *) in your browser to see how to locate the Eastern Conference table node - i.e. the *tag* name of the node, and maybe some defining *attributes*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Answer to Ex. 9.1.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solution\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "url = 'https://www.basketball-reference.com/leagues/NBA_2018.html'\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "html = response.text\n",
    "soup = BeautifulSoup(html,'lxml')\n",
    "\n",
    "table_node = soup.find('table',attrs={'id':'confs_standings_E'}) # find table node with specific attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have located the table should now build a function that starts at a \"table node\" and parses the information, and outputs a pandas DataFrame. \n",
    "\n",
    "Inspect the element either within the notebook or through the **>Inspector<** tool and start to see how a table is written in html. Which tag names can be used to locate rows? How will you iterate through columns. Were is the header located?\n",
    "\n",
    "> **Ex. 9.1.2:** First you parse the header which can be found in the canonical tag name: thead. \n",
    "Next you use the `find_all` method to search for the tag, and iterate through each of the elements extracting the text, using the `.text` method builtin to the the node object. Store the header values in a list container. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Answer to Ex. 9.1.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Eastern Conference', 'Wins', 'Losses', 'Win-Loss Percentage', 'Games Behind', 'Points Per Game', 'Opponent Points Per Game', 'Simple Rating System'] 8\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Solution\n",
    "name = table_node.caption.text\n",
    "# parse header\n",
    "header = table_node.thead.find_all('th') # locate each column name using the `th` tag, which entail a string .\n",
    "# extract the label you want. brevity use .text, for a more informative get teh aria-label attribute\n",
    "header = [col['aria-label'] for col in header]\n",
    "print(header,len(header))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 9.1.3:** Next you locate the rows, using the canonical tag name: tbody. And from here you search for all rows tags. Fiugre out the tag name yourself, inspecting the tbody node in python or using the **Inspector**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Answer to Ex. 9.1.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse rows: the canonical tbody locates the data body.\n",
    "body = table_node.tbody\n",
    "# rows are found using the \"tr\" tag\n",
    "rows = body.find_all('tr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 9.1.4:** Next run through all the rows and extract each value, similar to how you extracted the header. However here is a slight variation: Since each value node can have a different tag depending on whether it is a digit or a string, you should use the `.children` method instead of the `.find_all` - (or write compile a regex that matches both the td tag and the th tag.) \n",
    ">Once the value nodes of each row has been located using the `.children` method you should extract the value. Store the extracted rows as a list of lists: ```[[val1,val2,...valk],...]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Answer to Ex. 9.1.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each row value has different tags depending on their type (digit or string)\n",
    "# function to check what tag it is and either convert to float or not. \n",
    "import numpy as np\n",
    "def convert_value_type(value_node):\n",
    "    if value_node.name == 'th':\n",
    "        return value_node.text\n",
    "    else: # assume node is td:\n",
    "        try: \n",
    "            return float(value_node.text)\n",
    "        except:\n",
    "            return np.nan # assume there is no value if it fails. \n",
    "data = []\n",
    "for row_node in rows:\n",
    "    row = []\n",
    "    for child in row_node.children:\n",
    "        row.append(convert_value_type(child))\n",
    "    data.append(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 9.1.5:** Convert the data you have collected into a pandas dataframe. _Bonus:_ convert the code you've written above into a function which scrapes the page for you and returns a dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[Answer 9.1.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Eastern Conference</th>\n",
       "      <th>Wins</th>\n",
       "      <th>Losses</th>\n",
       "      <th>Win-Loss Percentage</th>\n",
       "      <th>Games Behind</th>\n",
       "      <th>Points Per Game</th>\n",
       "      <th>Opponent Points Per Game</th>\n",
       "      <th>Simple Rating System</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toronto Raptors* (1)</td>\n",
       "      <td>59.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.720</td>\n",
       "      <td>NaN</td>\n",
       "      <td>111.7</td>\n",
       "      <td>103.9</td>\n",
       "      <td>7.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Boston Celtics* (2)</td>\n",
       "      <td>55.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.671</td>\n",
       "      <td>4.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>100.4</td>\n",
       "      <td>3.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Philadelphia 76ers* (3)</td>\n",
       "      <td>52.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.634</td>\n",
       "      <td>7.0</td>\n",
       "      <td>109.8</td>\n",
       "      <td>105.3</td>\n",
       "      <td>4.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cleveland Cavaliers* (4)</td>\n",
       "      <td>50.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.610</td>\n",
       "      <td>9.0</td>\n",
       "      <td>110.9</td>\n",
       "      <td>109.9</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Indiana Pacers* (5)</td>\n",
       "      <td>48.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>11.0</td>\n",
       "      <td>105.6</td>\n",
       "      <td>104.2</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Eastern Conference  Wins  Losses  Win-Loss Percentage  Games Behind  \\\n",
       "0      Toronto Raptors* (1)   59.0    23.0                0.720           NaN   \n",
       "1       Boston Celtics* (2)   55.0    27.0                0.671           4.0   \n",
       "2   Philadelphia 76ers* (3)   52.0    30.0                0.634           7.0   \n",
       "3  Cleveland Cavaliers* (4)   50.0    32.0                0.610           9.0   \n",
       "4       Indiana Pacers* (5)   48.0    34.0                0.585          11.0   \n",
       "\n",
       "   Points Per Game  Opponent Points Per Game  Simple Rating System  \n",
       "0            111.7                     103.9                  7.29  \n",
       "1            104.0                     100.4                  3.23  \n",
       "2            109.8                     105.3                  4.30  \n",
       "3            110.9                     109.9                  0.59  \n",
       "4            105.6                     104.2                  1.18  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple answer\n",
    "df = pd.DataFrame(data,columns=header)\n",
    "\n",
    "# Bonus\n",
    "def parse_html_table(table_node):\n",
    "    # parse header\n",
    "    header = table_node.thead.find_all('th') # locate each column name using the `th` tag, which entail a string .\n",
    "    # extract the label you want. brevity use .text, for a more informative get teh aria-label attribute\n",
    "    header = [col['aria-label'] for col in header]\n",
    "    # parse rows: the canonical tbody locates the data body.\n",
    "    body = table_node.tbody\n",
    "    # rows are found using the \"tr\" tag\n",
    "    rows = body.find_all('tr')\n",
    "    # each row value has different tags depending on their type (digit or string)\n",
    "    # function to check what tag it is and either convert to float or not. \n",
    "    import numpy as np\n",
    "    def convert_value_type(value_node):\n",
    "        if value_node.name == 'th':\n",
    "            return value_node.text\n",
    "        else: # assume node is td:\n",
    "            try: \n",
    "                return float(value_node.text)\n",
    "            except:\n",
    "                return np.nan # assume there is no value if it fails. \n",
    "    data = []\n",
    "    for row_node in rows:\n",
    "        row = []\n",
    "        for child in row_node.children:\n",
    "            row.append(convert_value_type(child))\n",
    "        data.append(row)\n",
    "    df = pd.DataFrame(data,columns=header)\n",
    "    return df\n",
    "\n",
    "df = parse_html_table(table_node)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 9.1.6:** Now locate all tables from the page, using the `.find_all` method searching for the table tag name. Iterate through the table nodes and apply the function created for parsing html tables. Store each table in a dictionary using the table name as key. The name is found by accessing the id attribute of each table node, using dictionary-style syntax - i.e. `table_node['id']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Answer to Ex. 9.1.6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'confs_standings_E':            Eastern Conference  Wins  Losses  Win-Loss Percentage  \\\n",
       " 0       Toronto Raptors* (1)   59.0    23.0                0.720   \n",
       " 1        Boston Celtics* (2)   55.0    27.0                0.671   \n",
       " 2    Philadelphia 76ers* (3)   52.0    30.0                0.634   \n",
       " 3   Cleveland Cavaliers* (4)   50.0    32.0                0.610   \n",
       " 4        Indiana Pacers* (5)   48.0    34.0                0.585   \n",
       " 5            Miami Heat* (6)   44.0    38.0                0.537   \n",
       " 6       Milwaukee Bucks* (7)   44.0    38.0                0.537   \n",
       " 7    Washington Wizards* (8)   43.0    39.0                0.524   \n",
       " 8        Detroit Pistons (9)   39.0    43.0                0.476   \n",
       " 9     Charlotte Hornets (10)   36.0    46.0                0.439   \n",
       " 10      New York Knicks (11)   29.0    53.0                0.354   \n",
       " 11        Brooklyn Nets (12)   28.0    54.0                0.341   \n",
       " 12        Chicago Bulls (13)   27.0    55.0                0.329   \n",
       " 13        Orlando Magic (14)   25.0    57.0                0.305   \n",
       " 14        Atlanta Hawks (15)   24.0    58.0                0.293   \n",
       " \n",
       "     Games Behind  Points Per Game  Opponent Points Per Game  \\\n",
       " 0            NaN            111.7                     103.9   \n",
       " 1            4.0            104.0                     100.4   \n",
       " 2            7.0            109.8                     105.3   \n",
       " 3            9.0            110.9                     109.9   \n",
       " 4           11.0            105.6                     104.2   \n",
       " 5           15.0            103.4                     102.9   \n",
       " 6           15.0            106.5                     106.8   \n",
       " 7           16.0            106.6                     106.0   \n",
       " 8           20.0            103.8                     103.9   \n",
       " 9           23.0            108.2                     108.0   \n",
       " 10          30.0            104.5                     108.0   \n",
       " 11          31.0            106.6                     110.3   \n",
       " 12          32.0            102.9                     110.0   \n",
       " 13          34.0            103.4                     108.2   \n",
       " 14          35.0            103.4                     108.8   \n",
       " \n",
       "     Simple Rating System  \n",
       " 0                   7.29  \n",
       " 1                   3.23  \n",
       " 2                   4.30  \n",
       " 3                   0.59  \n",
       " 4                   1.18  \n",
       " 5                   0.15  \n",
       " 6                  -0.45  \n",
       " 7                   0.53  \n",
       " 8                  -0.26  \n",
       " 9                   0.07  \n",
       " 10                 -3.53  \n",
       " 11                 -3.67  \n",
       " 12                 -6.84  \n",
       " 13                 -4.92  \n",
       " 14                 -5.30  ,\n",
       " 'confs_standings_W':               Western Conference  Wins  Losses  Win-Loss Percentage  \\\n",
       " 0          Houston Rockets* (1)   65.0    17.0                0.793   \n",
       " 1    Golden State Warriors* (2)   58.0    24.0                0.707   \n",
       " 2   Portland Trail Blazers* (3)   49.0    33.0                0.598   \n",
       " 3    Oklahoma City Thunder* (4)   48.0    34.0                0.585   \n",
       " 4                Utah Jazz* (5)   48.0    34.0                0.585   \n",
       " 5     New Orleans Pelicans* (6)   48.0    34.0                0.585   \n",
       " 6        San Antonio Spurs* (7)   47.0    35.0                0.573   \n",
       " 7   Minnesota Timberwolves* (8)   47.0    35.0                0.573   \n",
       " 8            Denver Nuggets (9)   46.0    36.0                0.561   \n",
       " 9     Los Angeles Clippers (10)   42.0    40.0                0.512   \n",
       " 10      Los Angeles Lakers (11)   35.0    47.0                0.427   \n",
       " 11        Sacramento Kings (12)   27.0    55.0                0.329   \n",
       " 12        Dallas Mavericks (13)   24.0    58.0                0.293   \n",
       " 13       Memphis Grizzlies (14)   22.0    60.0                0.268   \n",
       " 14            Phoenix Suns (15)   21.0    61.0                0.256   \n",
       " \n",
       "     Games Behind  Points Per Game  Opponent Points Per Game  \\\n",
       " 0            NaN            112.4                     103.9   \n",
       " 1            7.0            113.5                     107.5   \n",
       " 2           16.0            105.6                     103.0   \n",
       " 3           17.0            107.9                     104.4   \n",
       " 4           17.0            104.1                      99.8   \n",
       " 5           17.0            111.7                     110.4   \n",
       " 6           18.0            102.7                      99.8   \n",
       " 7           18.0            109.5                     107.3   \n",
       " 8           19.0            110.0                     108.5   \n",
       " 9           23.0            109.0                     109.0   \n",
       " 10          30.0            108.1                     109.6   \n",
       " 11          38.0             98.8                     105.8   \n",
       " 12          41.0            102.3                     105.4   \n",
       " 13          43.0             99.3                     105.5   \n",
       " 14          44.0            103.9                     113.3   \n",
       " \n",
       "     Simple Rating System  \n",
       " 0                   8.21  \n",
       " 1                   5.79  \n",
       " 2                   2.60  \n",
       " 3                   3.42  \n",
       " 4                   4.47  \n",
       " 5                   1.48  \n",
       " 6                   2.89  \n",
       " 7                   2.35  \n",
       " 8                   1.57  \n",
       " 9                   0.15  \n",
       " 10                 -1.44  \n",
       " 11                 -6.60  \n",
       " 12                 -2.70  \n",
       " 13                 -5.81  \n",
       " 14                 -8.80  ,\n",
       " 'divs_standings_E':            Eastern Conference  Wins  Losses  Win-Loss Percentage  \\\n",
       " 0           Atlantic Division   NaN     NaN                  NaN   \n",
       " 1       Toronto Raptors* (1)   59.0    23.0                0.720   \n",
       " 2        Boston Celtics* (2)   55.0    27.0                0.671   \n",
       " 3    Philadelphia 76ers* (3)   52.0    30.0                0.634   \n",
       " 4       New York Knicks (11)   29.0    53.0                0.354   \n",
       " 5         Brooklyn Nets (12)   28.0    54.0                0.341   \n",
       " 6            Central Division   NaN     NaN                  NaN   \n",
       " 7   Cleveland Cavaliers* (4)   50.0    32.0                0.610   \n",
       " 8        Indiana Pacers* (5)   48.0    34.0                0.585   \n",
       " 9       Milwaukee Bucks* (7)   44.0    38.0                0.537   \n",
       " 10       Detroit Pistons (9)   39.0    43.0                0.476   \n",
       " 11        Chicago Bulls (13)   27.0    55.0                0.329   \n",
       " 12         Southeast Division   NaN     NaN                  NaN   \n",
       " 13           Miami Heat* (6)   44.0    38.0                0.537   \n",
       " 14   Washington Wizards* (8)   43.0    39.0                0.524   \n",
       " 15    Charlotte Hornets (10)   36.0    46.0                0.439   \n",
       " 16        Orlando Magic (14)   25.0    57.0                0.305   \n",
       " 17        Atlanta Hawks (15)   24.0    58.0                0.293   \n",
       " \n",
       "     Games Behind  Points Per Game  Opponent Points Per Game  \\\n",
       " 0            NaN              NaN                       NaN   \n",
       " 1            NaN            111.7                     103.9   \n",
       " 2            4.0            104.0                     100.4   \n",
       " 3            7.0            109.8                     105.3   \n",
       " 4           30.0            104.5                     108.0   \n",
       " 5           31.0            106.6                     110.3   \n",
       " 6            NaN              NaN                       NaN   \n",
       " 7            NaN            110.9                     109.9   \n",
       " 8            2.0            105.6                     104.2   \n",
       " 9            6.0            106.5                     106.8   \n",
       " 10          11.0            103.8                     103.9   \n",
       " 11          23.0            102.9                     110.0   \n",
       " 12           NaN              NaN                       NaN   \n",
       " 13           NaN            103.4                     102.9   \n",
       " 14           1.0            106.6                     106.0   \n",
       " 15           8.0            108.2                     108.0   \n",
       " 16          19.0            103.4                     108.2   \n",
       " 17          20.0            103.4                     108.8   \n",
       " \n",
       "     Simple Rating System  \n",
       " 0                    NaN  \n",
       " 1                   7.29  \n",
       " 2                   3.23  \n",
       " 3                   4.30  \n",
       " 4                  -3.53  \n",
       " 5                  -3.67  \n",
       " 6                    NaN  \n",
       " 7                   0.59  \n",
       " 8                   1.18  \n",
       " 9                  -0.45  \n",
       " 10                 -0.26  \n",
       " 11                 -6.84  \n",
       " 12                   NaN  \n",
       " 13                  0.15  \n",
       " 14                  0.53  \n",
       " 15                  0.07  \n",
       " 16                 -4.92  \n",
       " 17                 -5.30  ,\n",
       " 'divs_standings_W':               Western Conference  Wins  Losses  Win-Loss Percentage  \\\n",
       " 0             Northwest Division   NaN     NaN                  NaN   \n",
       " 1   Portland Trail Blazers* (3)   49.0    33.0                0.598   \n",
       " 2    Oklahoma City Thunder* (4)   48.0    34.0                0.585   \n",
       " 3                Utah Jazz* (5)   48.0    34.0                0.585   \n",
       " 4   Minnesota Timberwolves* (8)   47.0    35.0                0.573   \n",
       " 5            Denver Nuggets (9)   46.0    36.0                0.561   \n",
       " 6               Pacific Division   NaN     NaN                  NaN   \n",
       " 7    Golden State Warriors* (2)   58.0    24.0                0.707   \n",
       " 8     Los Angeles Clippers (10)   42.0    40.0                0.512   \n",
       " 9       Los Angeles Lakers (11)   35.0    47.0                0.427   \n",
       " 10        Sacramento Kings (12)   27.0    55.0                0.329   \n",
       " 11            Phoenix Suns (15)   21.0    61.0                0.256   \n",
       " 12            Southwest Division   NaN     NaN                  NaN   \n",
       " 13         Houston Rockets* (1)   65.0    17.0                0.793   \n",
       " 14    New Orleans Pelicans* (6)   48.0    34.0                0.585   \n",
       " 15       San Antonio Spurs* (7)   47.0    35.0                0.573   \n",
       " 16        Dallas Mavericks (13)   24.0    58.0                0.293   \n",
       " 17       Memphis Grizzlies (14)   22.0    60.0                0.268   \n",
       " \n",
       "     Games Behind  Points Per Game  Opponent Points Per Game  \\\n",
       " 0            NaN              NaN                       NaN   \n",
       " 1            NaN            105.6                     103.0   \n",
       " 2            1.0            107.9                     104.4   \n",
       " 3            1.0            104.1                      99.8   \n",
       " 4            2.0            109.5                     107.3   \n",
       " 5            3.0            110.0                     108.5   \n",
       " 6            NaN              NaN                       NaN   \n",
       " 7            NaN            113.5                     107.5   \n",
       " 8           16.0            109.0                     109.0   \n",
       " 9           23.0            108.1                     109.6   \n",
       " 10          31.0             98.8                     105.8   \n",
       " 11          37.0            103.9                     113.3   \n",
       " 12           NaN              NaN                       NaN   \n",
       " 13           NaN            112.4                     103.9   \n",
       " 14          17.0            111.7                     110.4   \n",
       " 15          18.0            102.7                      99.8   \n",
       " 16          41.0            102.3                     105.4   \n",
       " 17          43.0             99.3                     105.5   \n",
       " \n",
       "     Simple Rating System  \n",
       " 0                    NaN  \n",
       " 1                   2.60  \n",
       " 2                   3.42  \n",
       " 3                   4.47  \n",
       " 4                   2.35  \n",
       " 5                   1.57  \n",
       " 6                    NaN  \n",
       " 7                   5.79  \n",
       " 8                   0.15  \n",
       " 9                  -1.44  \n",
       " 10                 -6.60  \n",
       " 11                 -8.80  \n",
       " 12                   NaN  \n",
       " 13                  8.21  \n",
       " 14                  1.48  \n",
       " 15                  2.89  \n",
       " 16                 -2.70  \n",
       " 17                 -5.81  }"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution\n",
    "tables = soup.find_all('table') # locate all table nodes\n",
    "dfs = {}\n",
    "for table_node in tables:\n",
    "    name = table_node['id'] # access the id attribute. \n",
    "    table = parse_html_table(table_node) # apply parse_table function\n",
    "    dfs[name] = table # store table in the dictionary\n",
    "    \n",
    "    \n",
    "dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ** 9.1.extra.:** Compare your results to the pandas implementation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Section 9.2: Practicing Regular Expressions.\n",
    "This exercise is about developing your experience with designing your own regular expressions.\n",
    "\n",
    "Remember you can always consult the regular expression reference page [here](https://www.regular-expressions.info/refquick.html), if you need to remember or understand a specific symbol. \n",
    "\n",
    "You should practice using *\"define-inspect-refine-method\"* described in the lectures to systematically ***explore*** and ***refine*** your expressions, and save all the patterns tried. You can download the small module that I created to handle this in the following way: \n",
    "``` python\n",
    "import requests\n",
    "url = 'https://raw.githubusercontent.com/snorreralund/explore_regex/master/explore_regex.py'\n",
    "response = requests.get(url)\n",
    "with open('explore_regex.py','w') as f:\n",
    "    f.write(response.text)\n",
    "import explore_regex as e_re\n",
    "```\n",
    "\n",
    "Remember to start ***broad*** to gain many examples, and iteratively narrow and refine.\n",
    "\n",
    "We will use a sample of the trustpilot dataset that you practiced collecting yesterday.\n",
    "You can load it directly into python from the following link: https://raw.githubusercontent.com/snorreralund/scraping_seminar/master/english_review_sample.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 9.2.1:** Load the data used in the exercise using the `pd.read_csv` function. (Hint: path to file can be both a url or systempath). \n",
    "\n",
    ">Define a variable `sample_string = '\\n'.join(df.sample(2000).reviewBody)` as sample of all the reviews that you will practice on.  (Run it once in a while to get a new sample for potential differences).\n",
    "Imagine we were a company wanting to find the reviews where customers are concerned with the price of a service. They decide to write a regular expression to match all reviews where a currencies and an amount is mentioned. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Answer to Ex. 9.2.1]\n",
    "\n",
    "# This will be in assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 9.2.2:** \n",
    "> Write an expression that matches both the dollar-sign (\\$) and dollar written literally, and the amount before or after a dollar-sign. Remember that the \"$\"-sign is a special character in regular expressions. Explore and refine using the explore_pattern function in the package I created called explore_regex. \n",
    "```python\n",
    "import explore_regex as e_re\n",
    "explore_regex = e_re.Explore_Regex(sample_string) # Initaizlie the Explore regex Class.\n",
    "explore_regex.explore_pattern(pattern) # Use the .explore_pattern method.\n",
    "```\n",
    "\n",
    "\n",
    "Start with exploring the context around digits (\"\\d\") in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Answer to exercise 9.2.2] \n",
    "\n",
    "# This will be in assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex.9.2.3** Use the .report() method. e_re.report(), and print the all patterns in the development process using the .pattern method - i.e. e_re.patterns \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Answer 9.2.3]\n",
    "\n",
    "# This will be in assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">** Ex. 9.2.4** \n",
    "Finally write a function that takes in a string and outputs if there is a match. Use the .match function to see if there is a match (hint if does not return a NoneType object - `re.match(pattern,string)!=None`).\n",
    "\n",
    "> Define a column 'mention_currency' in the dataframe, by applying the above function to the text column of the dataframe. \n",
    "*** You should have approximately 310 reviews that matches. - but less is also alright***\n",
    "\n",
    "> **Ex. 9.2.5** Explore the relation between reviews mentioning prices and the average rating. \n",
    "\n",
    "> **Ex. 9.2.extra** Define a function that outputs the amount mentioned in the review (if more than one the largest), define a new column by applying it to the data, and explore whether reviews mentioning higher prices are worse than others by plotting the amount versus the rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[Answer to 9.2.4-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = '[£$] ?[0-9]+(?:[.,][0-9]+)?|[0-9]+(?:[.,][0-9]+)? ?(?:USD|usd)|[0-9]+(?:[.,][0-9]+)? ?(?:dollars|DOLLARS)'\n",
    "currency_re = re.compile(pattern)\n",
    "def match_currency(string):\n",
    "    return len(currency_re.findall(string))>0\n",
    "df['mention_currency'] = df.reviewBody.apply(match_currency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mention_currency\n",
       "False    4.507275\n",
       "True     2.935275\n",
       "Name: reviewRating_ratingValue, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('mention_currency').reviewRating_ratingValue.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 9.2.5:** Now we write a regular expression to extract emoticons from text.\n",
    "Start by locating all mouths ')' of emoticons, and develop the variations from there. Remember that paranthesis are special characters in regex, so you should use the escape character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_string = '\\n'.join(df.sample(1000).reviewBody)\n",
    "emoticon_regex = e_re.ExploreRegex(sample_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match: :)\tContext:me Aceable drivers. :)\n",
      "It is simple and ha\n",
      "Match: :-)\tContext:ieve 5 payday loans :-)\n",
      "Thank you so much f\n",
      "Match: :)\tContext:until we receive it :)\n",
      "Bluestone Perennial\n",
      "Match: :)\tContext:u for your business :). \r\n",
      "\r\n",
      "Angry customer\n",
      "Match: ;)\tContext:t says in the title ;)\n",
      "\n",
      "<3 Jani\n",
      "I Book a t\n",
      "Match: :)\tContext:ad a wonderful time :)\n",
      "Never had a problem\n"
     ]
    }
   ],
   "source": [
    "pattern = '[:;][-Oo]?[()D]'\n",
    "emoticon_regex.explore_pattern(pattern,context=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Pattern: [:;][-Oo]?[()D]\t Matched 6 patterns -----\n",
      "------ Pattern: [:][-Oo]?[()D]\t Matched 5 patterns -----\n"
     ]
    }
   ],
   "source": [
    "emoticon_regex.report(plot = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'[:;][-Oo]?[()D]': 6, '[:][-Oo]?[()D]': 5}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoticon_regex.pattern2n_match"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
